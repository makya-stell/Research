{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhoshm/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from geopy.distance import vincenty\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from mapbox import Geocoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# for tfidf stuff\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# the actual learner\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import cross_validation\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from googlemaps import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TweetAnalysis:\n",
    "    def __init__(self):\n",
    "        self.gmaps = Client(key='AIzaSyAj-bmP8U4Ast0nVszZ4Q1p6WKOFDi_Kxw')\n",
    "        self.mapbox_geo = Geocoder(access_token='pk.eyJ1Ijoic2FuYXJ5IiwiYSI6ImNqNmhjOGRvZzBnenIyeHJ5MWkza2k5am4ifQ.P__Hs0jv7Ea2dOyMAlbTeQ')\n",
    "    # this method makes a database query on text\n",
    "    def get_regular_loc(self,text):\n",
    "        if text is not None:\n",
    "            conn = sqlite3.connect('geonames.sqlite3')\n",
    "            c = conn.cursor()\n",
    "            try:\n",
    "                c.execute(\"select * from geoname where geonameid in (select geonameid from geoname_fts where geoname_fts match '\"+text+\"') order by population desc;\")\n",
    "                return c.fetchone()\n",
    "            except sqlite3.OperationalError:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def search_ngrams(self,text, limit=3):\n",
    "        '''tweet-tokenizes text and then searches all ngrams where n is [1,limit]'''\n",
    "        # check out https://github.com/petewarden/geodict\n",
    "        tknzr = TweetTokenizer()\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        places = []\n",
    "        for i in range(1,limit+1):\n",
    "            j = 0\n",
    "            while j+i <= len(tokens):\n",
    "                places.append(get_regular_loc(' '.join(tokens[j:j+i])))\n",
    "                j+=1\n",
    "        return places\n",
    "    \n",
    "    def get_center(self,coords):\n",
    "        # coords is a list of 4 points\n",
    "        xs,ys = zip(*coords)\n",
    "        return (sum(xs)/len(xs),sum(ys)/len(ys))\n",
    "    \n",
    "    def get_dist(self,p1,p2):\n",
    "        # gets the distance between 2 points using geopy\n",
    "        return vincenty(p1,p2).kilometers\n",
    "    def search_google(self,text):\n",
    "        result = self.gmaps.geocode(text)\n",
    "        if len(result) < 1:\n",
    "            return None\n",
    "        else:\n",
    "            return (result[0]['geometry']['location']['lng'],result[0]['geometry']['location']['lat'])\n",
    "    def search_mapbox_center(self,text):\n",
    "        result = self.mapbox_geo.forward(text).geojson()\n",
    "        if len(result['features']) < 1:\n",
    "            return None\n",
    "        else:\n",
    "            return (result['features'][0]['center'][0],result['features'][0]['center'][1])\n",
    "    def search_mapbox_region(self,text):\n",
    "        result = self.mapbox_geo.forward(text).geojson()\n",
    "        if len(result['features']) < 1:\n",
    "            return None\n",
    "        else:\n",
    "            return ((result['features'][0]['bbox'][0],result['features'][0]['bbox'][1]),(result['features'][0]['bbox'][2],result['features'][0]['bbox'][3]))\n",
    "    def get_x_dist(self,p1,p2):\n",
    "        return self.get_dist(p1,(p2[0], p1[1]))\n",
    "    def get_y_dist(self,p1,p2):\n",
    "        return self.get_dist(p1,(p1[0],p2[1]))\n",
    "    \n",
    "    def get_mean_dist_and_var(self, tweet):\n",
    "        if tweet['user']['location'] is None:\n",
    "            return None\n",
    "        result = self.mapbox_geo.forward(tweet['user']['location']).geojson()\n",
    "        try:\n",
    "            if len(result['features']) < 1:\n",
    "                return None\n",
    "            user_loc_box = result['features'][0]['bbox']\n",
    "            user_loc_center = result['features'][0]['center']\n",
    "            tweet_box = tweet['place']['bounding_box']['coordinates'][0]\n",
    "            tweet_center = self.get_center(tweet['place']['bounding_box']['coordinates'][0])\n",
    "        except:\n",
    "            return None\n",
    "        # we just want the horizontal distance here, so we have to manipulate the coordinates a bit\n",
    "        xdist = self.get_x_dist(user_loc_center,tweet_center)\n",
    "        ydist = self.get_y_dist(user_loc_center,tweet_center)\n",
    "        total_dist = (xdist**2 + ydist**2)**0.5\n",
    "        #now for the variations\n",
    "        user_loc_x_var = (1.0/12) * self.get_x_dist((user_loc_box[0],user_loc_box[1]),(user_loc_box[2],user_loc_box[3]))**2\n",
    "        user_loc_y_var = (1.0/12) * self.get_y_dist((user_loc_box[0],user_loc_box[1]),(user_loc_box[2],user_loc_box[3]))**2\n",
    "        tweet_x_var = (1.0/12) * self.get_dist(tweet_box[1],tweet_box[2])**2\n",
    "        tweet_y_var = (1.0/12) * self.get_dist(tweet_box[0],tweet_box[1])**2\n",
    "        total_x_var = user_loc_x_var + tweet_x_var\n",
    "        total_y_var = user_loc_y_var + tweet_y_var\n",
    "        total_std_dev = (total_x_var + total_y_var)**0.5\n",
    "\n",
    "        return total_dist,total_std_dev\n",
    "    \n",
    "    def check_user_loc_distance(self, tweet):\n",
    "        if tweet['user']['location'] is None:\n",
    "            return None\n",
    "        user_loc = self.search_mapbox_center(tweet['user']['location'])\n",
    "        if user_loc is None:\n",
    "            return None\n",
    "        else:\n",
    "            return selg.get_dist(user_loc, get_center(tweet['place']['bounding_box']['coordinates'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ta = TweetAnalysis()\n",
    "    tweets = []\n",
    "    counter = 0\n",
    "    distances = []\n",
    "    start = time.time()\n",
    "    tweetfile = 'gina-tweets.json'\n",
    "    limit = 500000\n",
    "    with open(tweetfile,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tweets.append(json.loads(line))\n",
    "            l=ta.get_mean_dist_and_var(tweets[-1])\n",
    "            print(l)\n",
    "            distances.append(l)\n",
    "            counter += 1\n",
    "            if counter % 599 == 0:\n",
    "                # sleep until the next 60 second interval\n",
    "                time.sleep(61-((time.time()-start)%60))\n",
    "            if counter >= limit: break\n",
    "\n",
    "    # the machine learning stuff\n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "    transformer = TfidfTransformer()\n",
    "    corpus = [t['user']['description'] + ' ' + t['user']['location'] for t in tweets if t['user']['description'] is not None and t['user']['location'] is not None]\n",
    "    #use last 10% as test\n",
    "    train = corpus[:int(len(corpus)*.9)]\n",
    "    test = corpus[-int(len(corpus)*.1):]\n",
    "    X = vectorizer.fit_transform(train)\n",
    "    tfidf = transformer.fit_transform(X)\n",
    "    coord1 = [ta.get_center(t['place']['bounding_box']['coordinates'][0])[0] for t in tweets if t['user']['description'] is not None and t['user']['location'] is not None]\n",
    "    coord1_train = coord1[:len(train)]\n",
    "    coord1_test = coord1[len(train):]\n",
    "    clf1 = SVR()\n",
    "    clf1.fit(tfidf, coord1_train)\n",
    "    coord2 = [ta.get_center(t['place']['bounding_box']['coordinates'][0])[1] for t in tweets if t['user']['description'] is not None and t['user']['location'] is not None]\n",
    "    coord2_train = coord2[:len(train)]\n",
    "    coord2_test = coord2[len(train):]\n",
    "    clf2 = SVR()\n",
    "    # use last 10% as test\n",
    "    clf2.fit(tfidf, coord2_train)\n",
    "\n",
    "    s = min([int(t['timestamp_ms']) for t in tweets])/1000\n",
    "    f = max([int(t['timestamp_ms']) for t in tweets])/1000\n",
    "    print('start: {0}\\tend{1}'.format(datetime.datetime.fromtimestamp(s),datetime.datetime.fromtimestamp(f)))\n",
    "\n",
    "    found = [d[0] for d in distances if d is not None]\n",
    "    plt.hist(found)\n",
    "    plt.title('Error as Distance From Centers')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    #plt.savefig('Error')\n",
    "\n",
    "    found = [d[0] for d in distances if d is not None and d[0]<1000]\n",
    "    plt.hist(found)\n",
    "    plt.title('Filtered Error as Distance From Centers')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    #plt.savefig('Filtered')\n",
    "\n",
    "    found = [d[1] for d in distances if d is not None]\n",
    "    plt.hist(found)\n",
    "    plt.title('Error as Standard Deviations Between Regions')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    #plt.savefig('errorsd')\n",
    "\n",
    "    test_transform = transformer.transform(vectorizer.transform(test))\n",
    "    preds = zip(clf1.predict(test_transform),clf2.predict(test_transform))\n",
    "    test_points = list(zip(coord1_test,coord2_test))\n",
    "    errs = [get_dist(p,test_points[i]) for i,p in enumerate(preds)]\n",
    "    plt.hist(errs)\n",
    "    plt.title('Error of Predicted Location by Distance')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    #plt.savefig('epl')\n",
    "    #todo plot error histogram,think about filter & histogram,&svr histogram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
